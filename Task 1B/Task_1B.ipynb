{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1B: Fruit classification with a CNN\n",
    "\n",
    "This notebook will serve as implementation of the API that you have created in your \"Code\" folder. You will write functions in the \"py\" files and use them here.\n",
    "\n",
    "We will be using \"Fruits\" dataset present in PyTorch and train a convolutional neural network (CNN) to classify digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is expected from this notebook?\n",
    "\n",
    "This notebook should be used to present your work. You should explain wherever necessary (but also not too much) about what you did and why you did it. You should explain things like hyper parameter settings (even if it was provided before hand to you by us), training performance and testing performance of the model. You should reason why your model is working fine and not overfitting.\n",
    "\n",
    "Since numbers don't are an argot, you should also use visualizations wherever possible. You can visualize things like **loss curve**, show **confusion matrix** and since this is a CNN you can also consider **advance techniques like gradcam**, etc. \n",
    "\n",
    "You can also use techniques that allow for faster training, assuage problems involving vanishing and exploding gradients. \n",
    "\n",
    "Finally, you can show some manual verifications by displaying and making predictions on random test examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolutely required items?\n",
    "\n",
    "1. First of all, import the libraries and the dataset. Divide the dataset into test and train.\n",
    "2. Next, show dataset samples and distribution of different type of data. For example, in case of \"Fruits Dataset\" you can show some random images and their labels. Also, show distribution of each class of images.\n",
    "3. Next, perform required transformations (also **data augmentation**) on \"Fruits dataset\" (normalization, resizing, grayscaling, if required, etc.) using torchvision transforms.\n",
    "4. Create required dataloaders with PyTorch and use the module dataset we created to load data in mini-batches.\n",
    "5. Train the model, show loss and accuracy at each step of operation.\n",
    "6. Plot the **loss curve for both train and validation phase**.\n",
    "7. Pick some manual random images (probably 7-10) from test dataset and predict their values showing **expected and actual result**. \n",
    "\n",
    "**NOTE: ** \n",
    "1. You may or may not choose to delete these instruction cells after completion of the notebook.\n",
    "2. Keep the outputs of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset\n",
    "import torchvision\n",
    "from model import FNet\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "\n",
    "# import other required libraries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_and_load_meta_csv_df() got an unexpected keyword argument 'dest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-33ee3213d59d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading dataframes using dataset module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_and_load_meta_csv_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../Data/fruits/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../Data/fruits/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: create_and_load_meta_csv_df() got an unexpected keyword argument 'dest'"
     ]
    }
   ],
   "source": [
    "# loading dataframes using dataset module\n",
    "from utils import dataset\n",
    "df, df_train, df_test = dataset.create_and_load_meta_csv_df(dataset_path='../Data/fruits/', dest='../Data/fruits/', randomize=True, split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dataframes, pytorch and torchvision to transform data. Also, use dataloaders for batching, shuffling, etc.  \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # add transforms here\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        # add transforms here\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {'train': dataset.ImageDataset(df_train, transform=data_transforms['train']), \n",
    "                  'val': dataset.ImageDataset(df_test, transform=data_transforms['val'])}\n",
    "\n",
    "dataloaders_train = torch.utils.data.DataLoader(dataset=image_datasets['train'],\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "model = FNet( num_classes).to(device)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug == True:\n",
    "        for epoch in range(num_epochs):\n",
    "          for i, (images, labels) in enumerate(train_loader):\n",
    "              images = images.to(device)\n",
    "              labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "              outputs = model(images)\n",
    "              loss = criterion(outputs, labels)\n",
    "          \n",
    "        # Backward and optimize\n",
    "              optimizer.zero_grad()\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "          \n",
    "              if (i+1) % 5 == 0 and debug == True:\n",
    "                      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "                  \n",
    "    \n",
    "    \n",
    "    \n",
    "if destination_path == '':\n",
    "        \n",
    "        torch.save(model.state_dict(), 'model.ckpt')\n",
    "    \n",
    "else:\n",
    "              \n",
    "          DATASET_PATH = os.path.abspath(dataset_path)\n",
    "          torch.save(model.state_dict(), os.path.join(DATASET_PATH, \"/model.ckpt\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
